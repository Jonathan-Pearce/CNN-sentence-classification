{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "551_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "qK6H8oJ3pHPe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Comp 551 Project 4 "
      ]
    },
    {
      "metadata": {
        "id": "cnTFiyM5tBl1",
        "colab_type": "code",
        "outputId": "11255485-093b-48f6-eb82-0466c990dc27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Block 1\n",
        "#Imports\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import io\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import random_uniform\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers import Reshape\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.backend import expand_dims\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate, concatenate\n",
        "from keras.layers import merge\n",
        "from keras.initializers import RandomUniform\n",
        "from keras.constraints import max_norm\n",
        "from keras.constraints import MaxNorm\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ATlesKRNhlI2",
        "colab_type": "code",
        "outputId": "f0e0bd2e-f63e-48e7-ac6d-beb7d001fbbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#2\n",
        "#Downloads\n",
        "nltk.download('punkt') #I had to run this line as well"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "_0t3VoMSFTA2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#3\n",
        "#input = list of raw sentences\n",
        "#output = list of formatted sentences\n",
        "def processData(data):\n",
        "  sentences = []\n",
        "  for line in data:\n",
        "    \n",
        "    #remove all non Alphanumeric characters\n",
        "    #also keep exclamation and question marks as they can express sentiment\n",
        "    #Replace with spaces\n",
        "    line = re.sub(r\"[^A-Za-z0-9!?]\", \" \", line)\n",
        "    #seperate question marks and exclamation marks from text\n",
        "    line = re.sub(r\"!\", \" ! \", line)  \n",
        "    line = re.sub(r\"\\?\", \" ? \", line) \n",
        "    \n",
        "    #lower case\n",
        "    line = line.lower()\n",
        "    #whitespace at beggining and end of sentence\n",
        "    line = line.strip()\n",
        "    \n",
        "    #remove excess whitespace in the middle of each sentence\n",
        "    line = ' '.join(line.split())\n",
        "    \n",
        "    #add to list\n",
        "    sentences.append(line);\n",
        "  return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "avTVOxLBUGH0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#4\n",
        "#for MPQA dataset\n",
        "#sort according to label at the start of the sentence\n",
        "def sortResponses(data):\n",
        "  pos = []\n",
        "  neg = []\n",
        "  \n",
        "  for line in data:\n",
        "    index = int(line[0:1])\n",
        "    \n",
        "    if index == 1:\n",
        "      pos.append(line[1:])\n",
        "    else:\n",
        "      neg.append(line[1:])\n",
        "      \n",
        "  return (pos,neg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xi8VW6ymaSfl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#5\n",
        "#calculate size of dataset vocabulary - needed to intialize one hot vectors\n",
        "def vocabSize(data):\n",
        "  P = {' '} \n",
        "\n",
        "  for line in data:\n",
        "    #split at spaces\n",
        "    words = line.split(' ')\n",
        "    \n",
        "    for i in words:\n",
        "      P.add(i)\n",
        "  \n",
        "  print(len(P))\n",
        "  return len(P)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "suui67k0fblp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Note: Only run Block 6,7 or 8 depending on which dataset you're testing\n"
      ]
    },
    {
      "metadata": {
        "id": "GyvoDtyczo5s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#6\n",
        "#MR data\n",
        "\n",
        "#Read data\n",
        "positive = io.open('rt-polarity.pos', encoding = \"ISO-8859-1\")\n",
        "negative = io.open('rt-polarity.neg', encoding = \"ISO-8859-1\")\n",
        "\n",
        "\n",
        "pos = processData(positive)\n",
        "neg = processData(negative)\n",
        "\n",
        "pos[0:10]\n",
        "\n",
        "#combine to create full sentence dataset\n",
        "X = pos + neg\n",
        "#print(len(X))\n",
        "\n",
        "#responses positive = 1, negative = 0\n",
        "y = [1]*len(pos) + [0]*len(neg)\n",
        "#len(y)\n",
        "\n",
        "vocab_size = vocabSize(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lee9DwD-xMW9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#7\n",
        "#Subj Data\n",
        "objective = io.open('plot.tok.gt9.5000', encoding = \"ISO-8859-1\")\n",
        "subjective = io.open('quote.tok.gt9.5000', encoding = \"ISO-8859-1\")\n",
        "\n",
        "\n",
        "sub = processData(subjective)\n",
        "obj = processData(objective)\n",
        "\n",
        "#combine to create full sentence dataset\n",
        "X = sub + obj\n",
        "#print(len(X))\n",
        "\n",
        "y = [1]*len(sub) + [0]*len(obj)\n",
        "len(y)\n",
        "\n",
        "vocab_size = vocabSize(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKEpVff9T-ku",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#8\n",
        "#MPQA Data\n",
        "mpqa = io.open('mpqa.all', encoding = \"ISO-8859-1\")\n",
        "\n",
        "pos,neg = sortResponses(mpqa)\n",
        "\n",
        "pos = processData(pos)\n",
        "neg = processData(neg)\n",
        "\n",
        "\n",
        "#combine to create full sentence dataset\n",
        "X = pos + neg\n",
        "#print(len(X))\n",
        "\n",
        "y = [1]*len(pos) + [0]*len(neg)\n",
        "\n",
        "print(len(pos))\n",
        "print(len(neg))\n",
        "print(len(X))\n",
        "print(len(y))\n",
        "print(pos[0:10])\n",
        "print(neg[0:10])\n",
        "\n",
        "vocab_size = vocabSize(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xhlo3nJB8JAy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#9\n",
        "#convert words to integers\n",
        "#i.e. sentences go from sets of words to integers representing each word\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in X]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZriAgm-48x1B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#10\n",
        "#Have to get the maximum length sentence in order to pad all sentences\n",
        "maxLength = 0\n",
        "\n",
        "for i in encoded_docs:\n",
        "  if len(i) > maxLength:\n",
        "    maxLength = len(i)\n",
        "\n",
        "\n",
        "#Without this the first and last words of the longest sentence would only be considered once! by the convolutions\n",
        "maxLength += 8\n",
        "\n",
        "maxLength \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fS5HOAO2fJSu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#11\n",
        "\n",
        "#centering sentences with zero padding\n",
        "#not explicitly mentioned in paper but is in Collobert et. al. 2011\n",
        "\n",
        "padded_docs = np.zeros((len(y), maxLength))\n",
        "\n",
        "print(len(encoded_docs))\n",
        "\n",
        "for i in range(len(encoded_docs)):\n",
        "\n",
        "  length = len(encoded_docs[i])\n",
        "  \n",
        "  pad_end = int((maxLength - length)/2)\n",
        "  \n",
        "  pad_front = maxLength - length - pad_end\n",
        "\n",
        "  #add zero padding\n",
        "  padVector = [0] * pad_front + encoded_docs[i] + [0]*pad_end\n",
        "\n",
        "  padded_docs[i] = padVector\n",
        "  \n",
        "  \n",
        "#print(padded_docs[0:10])\n",
        "print(padded_docs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2TCB5ZlaoDSi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#12\n",
        "#convert labels to categorical data (this ensures it works with the final softmax layer)\n",
        "y = np.asarray(y)\n",
        "y = to_categorical(y)\n",
        "print(len(y))\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A4b1hfAfYqE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#13\n",
        "X_array = np.asarray(padded_docs)\n",
        "print(X_array.shape)\n",
        "print(X_array[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y8T_qmnp7B07",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#14\n",
        "\n",
        "#80% of data is used in training. The remainder is split 50/50 between validation and test sets \n",
        "\n",
        "train_prop = 0.8\n",
        "valid_prop = 0.5\n",
        "\n",
        "\n",
        "#80% of data into training set, 20% for validation and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_array, y, train_size=train_prop, random_state=7)\n",
        "\n",
        "#Divide 20% of test data 50/50 between test and validation sets \n",
        "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=valid_prop, random_state=9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddG7caxItAGj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#15\n",
        "print(len(X_train))\n",
        "print(len(X_valid))\n",
        "print(len(X_test))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F4ZbouRnGb8i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN Architecture"
      ]
    },
    {
      "metadata": {
        "id": "3kX0EGa4igkG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#16\n",
        "#Paramters\n",
        "\n",
        "#from paper explicitly\n",
        "filter_Sizes = [3,4,5]\n",
        "feature_Maps = 100\n",
        "p = 0.5\n",
        "l2 = 3\n",
        "mini_Batch_Size = 50\n",
        "\n",
        "#inferred from context\n",
        "embedding_Length = 300\n",
        "a = 0.245"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AAuVwhuD8xK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#17\n",
        "inputs = Input(shape=(maxLength,))#fix input\n",
        "\n",
        "#equal min and max are based on notes on page 5\n",
        "#they don't specify what alpha is though, only that variance is the same as word2vec variance\n",
        "#https://aclweb.org/anthology/D17-1127 says variance of word2vec is ~0.02, working backwards you get that we should sample from U[-0.245,0.245]\n",
        "em = Embedding(vocab_size, embedding_Length, embeddings_initializer = RandomUniform(minval= -a, maxval=a, seed=None), input_length=maxLength)(inputs)\n",
        "\n",
        "#add last dimension\n",
        "em = Reshape(target_shape=(maxLength,embedding_Length,1))(em)\n",
        "\n",
        "#Three submodels - each submodel for a differnt kernel size\n",
        "#Submodel performs convolution (100 feature maps each) and then does MaxPool\n",
        "sm1 = Conv2D(feature_Maps, kernel_size=(filter_Sizes[0],embedding_Length), padding='valid', activation='relu', strides=1)(em)\n",
        "sm1 = MaxPooling2D(pool_size=(maxLength-filter_Sizes[0]+1, 1), strides=(1,1))(sm1)\n",
        "\n",
        "sm2 = Conv2D(feature_Maps, kernel_size=(filter_Sizes[1],embedding_Length), padding='valid', activation='relu', strides=1)(em)\n",
        "sm2 = MaxPooling2D(pool_size=(maxLength-filter_Sizes[1]+1, 1), strides=(1,1))(sm2)\n",
        "\n",
        "sm3 = Conv2D(feature_Maps, kernel_size=(filter_Sizes[2],embedding_Length), padding='valid', activation='relu', strides=1)(em)\n",
        "sm3 = MaxPooling2D(pool_size=(maxLength-filter_Sizes[2]+1, 1), strides=(1,1))(sm3)\n",
        "\n",
        "#combine \"outputs\" from each \"sub-model\" to from penultimate layer\n",
        "#300 x 1 layer\n",
        "m = concatenate([sm1, sm2, sm3],axis=3)\n",
        "m = Flatten()(m)\n",
        "\n",
        "#regularization methods on penultimate layer\n",
        "#Dropout\n",
        "#l2-norm constraint is in Dense layer below\n",
        "m = Dropout(p)(m)\n",
        "#predict using softmax\n",
        "predictions = Dense(2, activation='softmax',kernel_constraint=max_norm(l2))(m)\n",
        "\n",
        "\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer='adaDelta',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Ow0Jlwwv8FZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#18\n",
        "\n",
        "#save each iteration of network\n",
        "filepath=\"weights.{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JjqQTVdqc_Gz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#19\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=mini_Batch_Size, validation_data=(X_valid, y_valid),callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LnjHf-y1ihnT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#20\n",
        "#Accuracy Plot\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('CNN-rand Replication Accuracy on MPQA dataset')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training set', 'validation set'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mo5__W6z5YnA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#21\n",
        "#Loss Plot\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('CNN-rand Replication Loss on MPQA dataset')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training set', 'validation set'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0WTLLSxgrMp8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#22\n",
        "print(history.history['acc'])\n",
        "print(history.history['val_acc'])\n",
        "print(history.history['loss'])\n",
        "print(history.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z1wL14X3xskl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#23\n",
        "#Model evaluation using test set\n",
        "\n",
        "#load in the first model (epoch #) that had the validation accuracy not increase for 5 epochs after\n",
        "model.load_weights(\"weights.11.hdf5\")\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adaDelta', metrics=['accuracy'])\n",
        "\n",
        "scores = model.evaluate(X_test, y_test,verbose=1)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TewOF5X34WO4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#24\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}